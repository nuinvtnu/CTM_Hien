{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"x7LBfh0uLpup","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d28caac-ada7-4d22-aca7-d05e5089a363","executionInfo":{"status":"ok","timestamp":1732870340500,"user_tz":-420,"elapsed":20207,"user":{"displayName":"CÙ THỊ MAI HIÊN","userId":"13472880489405816895"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HOc-mgrK5B_6","executionInfo":{"status":"ok","timestamp":1732870348944,"user_tz":-420,"elapsed":8449,"user":{"displayName":"CÙ THỊ MAI HIÊN","userId":"13472880489405816895"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import pickle as cPickle\n","import pandas as pd\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n","import sklearn.metrics\n","from sklearn.metrics import confusion_matrix\n","\n","from sklearn.model_selection import KFold\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n","from keras.layers import concatenate\n","from tensorflow.keras import Model\n","from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional\n","from keras import models"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Mt34EtLoLpup","executionInfo":{"status":"ok","timestamp":1732870348945,"user_tz":-420,"elapsed":6,"user":{"displayName":"CÙ THỊ MAI HIÊN","userId":"13472880489405816895"}}},"outputs":[],"source":["path_data = \"/content/drive/MyDrive/CTM_Hien-main/Data/\"\n","path_result = \"/content/drive/MyDrive/CTM_Hien-main/Result/\"\n","path_model = \"/content/drive/MyDrive/CTM_Hien-main/Model/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUUYvlp8Lpup"},"outputs":[],"source":["# Định nghĩa từ điển axit amin cấu tạo nên chuỗi protein\n","def twoTupleDic3(): # Từ điển 3-gram\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        for j in AA_list_sort:\n","          for jj in AA_list_sort:\n","             AA_dict[i+j+jj] = numm\n","             numm += 1\n","    return AA_dict\n","def twoTupleDic2(): # Từ điển 2-gram\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        for j in AA_list_sort:\n","          AA_dict[i+j] = numm\n","          numm += 1\n","    return AA_dict\n","\n","def twoTupleDic1(): # Từ điển 1-gram\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        AA_dict[i] = numm\n","        numm += 1\n","    return AA_dict\n","def ProSentence(pro, K):\n","\tsentence = \"\"\n","\tlength = len(pro)\n","\tfor i in range(length - K + 1):\n","\t\tsentence += pro[i: i + K] + \" \"\n","    #delete extra space\n","\tsentence = sentence[0 : len(sentence) - 1]\n","\treturn sentence\n","k =1#1-gram\n","word_index1 = twoTupleDic1()\n","vocab_size = len(word_index1)\n","\n","TIME_STEPS = 33\n","INPUT_SIZE = 300"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QeJNsISDLput","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a285be6-ada0-40eb-d40c-c7c92ca46d84","executionInfo":{"status":"ok","timestamp":1732870349889,"user_tz":-420,"elapsed":948,"user":{"displayName":"CÙ THỊ MAI HIÊN","userId":"13472880489405816895"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6746, 2)"]},"metadata":{},"execution_count":5}],"source":["# Tải dữ liệu train model\n","import pandas as pd\n","file_train = \"train_data_3speaces_31.csv\"\n","df_train=pd.read_csv(path_data + file_train, delimiter= ',')\n","\n","texts_train =[] #PTMsequend kmer\n","for i in df_train['Sequence']:\n","  temp = ProSentence(i,k)\n","  texts_train.append(temp)\n","df_train['k_mer'] =texts_train\n","train_sequences = []\n","for each in texts_train:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    train_sequences.append(each_index_list)\n","# Tokenizer train data input Word2vec\n","data_token = []\n","for i in df_train['k_mer']:\n","   data_token.append(i.split())\n","\n","MAX_SEQUENCE_LENGTH= len(data_token[1])\n","Xtrain = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","ytrain = np.array(df_train['Label'])\n","ytrain = np.array(ytrain)\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","ytrain = lb.fit_transform(ytrain)\n","ytrain= to_categorical(ytrain)\n","ytrain.shape\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"rkImwNniLput","colab":{"base_uri":"https://localhost:8080/"},"outputId":"19d794f1-6e5c-4230-ba38-5485d06dba73","executionInfo":{"status":"ok","timestamp":1732870349889,"user_tz":-420,"elapsed":7,"user":{"displayName":"CÙ THỊ MAI HIÊN","userId":"13472880489405816895"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6746, 2)"]},"metadata":{},"execution_count":6}],"source":["# Tải dữ liệu test\n","file_test=\"train_data_3speaces_31.csv\"\n","df_test =pd.read_csv(path_data +file_test,delimiter= ',')\n","text_test =[] #PTMsequend kmerpath_\n","for i in df_test['Sequence']:\n","  temp = ProSentence(i,k)\n","  text_test.append(temp)\n","df_test['k_mer'] =text_test\n","\n","test_sequences = []\n","for each in text_test:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    test_sequences.append(each_index_list)\n","\n","Xtest = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","ytest = np.array(df_test['Label'])\n","# perform one-hot encoding on the labels\n","ytest= np.array(ytest)\n","lb = LabelBinarizer()\n","ytest= lb.fit_transform(ytest)\n","ytest = to_categorical(ytest)\n","ytest.shape"]},{"cell_type":"markdown","source":["ĐỊnh nghĩa mô hình chắt lọc tri thức"],"metadata":{"id":"Hud3BNBGkcH_"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"o92YRtPh5Knd","executionInfo":{"status":"ok","timestamp":1732870350234,"user_tz":-420,"elapsed":349,"user":{"displayName":"CÙ THỊ MAI HIÊN","userId":"13472880489405816895"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"23d94fee-5912-4371-e391-87bb8a80e0ad"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]}],"source":["class Distiller(keras.Model):\n","    def __init__(self, student, teacher):\n","        super().__init__()\n","        self.teacher = teacher\n","        self.student = student\n","\n","    def compile(\n","        self,\n","        optimizer,\n","        metrics,\n","        student_loss_fn,\n","        distillation_loss_fn,\n","        alpha=0.1,\n","        temperature=3,\n","    ):\n","        \"\"\" Configure the distiller.\n","\n","        Args:\n","            optimizer: Keras optimizer for the student weights\n","            metrics: Keras metrics for evaluation\n","            student_loss_fn: Loss function of difference between student\n","                predictions and ground-truth\n","            distillation_loss_fn: Loss function of difference between soft\n","                student predictions and soft teacher predictions\n","            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n","            temperature: Temperature for softening probability distributions.\n","                Larger temperature gives softer distributions.\n","        \"\"\"\n","        super().compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = student_loss_fn\n","        self.distillation_loss_fn = distillation_loss_fn\n","        self.alpha = alpha\n","        self.temperature = temperature\n","\n","    def train_step(self, data):\n","        # Unpack data\n","        x, y = data\n","\n","        # Forward pass of teacher\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            # Forward pass of student\n","            student_predictions = self.student(x, training=True)\n","\n","            # Compute losses\n","            student_loss = self.student_loss_fn(y, student_predictions)\n","\n","            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n","            # The magnitudes of the gradients produced by the soft targets scale\n","            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n","            distillation_loss = (\n","                self.distillation_loss_fn(\n","                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n","                )\n","                * self.temperature**2\n","            )\n","\n","            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n","\n","        # Compute gradients\n","        trainable_vars = self.student.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        # Update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","        # Update the metrics configured in `compile()`.\n","        self.compiled_metrics.update_state(y, student_predictions)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update(\n","            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n","        )\n","        return results\n","\n","    def test_step(self, data):\n","        # Unpack the data\n","        x, y = data\n","\n","        # Compute predictions\n","        y_prediction = self.student(x, training=False)\n","\n","        # Calculate the loss\n","        student_loss = self.student_loss_fn(y, y_prediction)\n","\n","        # Update the metrics.\n","        self.compiled_metrics.update_state(y, y_prediction)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update({\"student_loss\": student_loss})\n","        return results\n","teacher = keras.Sequential(\n","    [\n","        layers.Embedding(vocab_size+1, 300, input_length=MAX_SEQUENCE_LENGTH,trainable=True),\n","        #layers.dropout(0.2),\n","        layers.LSTM(300, dropout=0.2, recurrent_dropout=0.2),\n","        layers.Dropout(0.2),\n","        #layers.LSTM(300, dropout=0.2, recurrent_dropout=0.2),\n","        layers.Flatten(),\n","        layers.Dense(128),\n","        layers.Dropout(0.2),\n","        layers.Dense(2),\n","        layers.Activation('softmax'),\n","\n","    ],\n","    name=\"teacher\",\n",")\n","\n","teacher.compile(\n","    loss=keras.losses.CategoricalCrossentropy(),\n","    metrics=[\n","        \"categorical_accuracy\",\n","        \"AUC\",\n","\n","    ],\n","    optimizer=keras.optimizers.AdamW(learning_rate=0.0001),\n",")\n","student = keras.Sequential(\n","    [\n","        layers.Embedding(vocab_size+1, 300, input_length=MAX_SEQUENCE_LENGTH,trainable=True),\n","        #layers.dropout(0.2),\n","        layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n","        layers.Dropout(0.2),\n","        #layers.LSTM(300, dropout=0.2, recurrent_dropout=0.2),\n","        layers.Flatten(),\n","        layers.Dense(128),\n","        layers.Dropout(0.2),\n","        layers.Dense(2),\n","        layers.Activation('softmax'),\n","    ],\n","    name=\"student\",\n",")\n","student_scratch = keras.models.clone_model(student)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"O336skmC67je","executionInfo":{"status":"ok","timestamp":1732870350234,"user_tz":-420,"elapsed":7,"user":{"displayName":"CÙ THỊ MAI HIÊN","userId":"13472880489405816895"}}},"outputs":[],"source":["checkpoint = EarlyStopping(monitor='val_loss',\n","            min_delta=0,\n","            patience=3,\n","            verbose=1, mode='auto')\n","result_test =path_result +\"Result_KD.txt\"\n"]},{"cell_type":"markdown","source":["Knowledge Distillation base on LSTM"],"metadata":{"id":"jm_l7Hy3whr1"}},{"cell_type":"code","source":["# Huấn luyện mô hình teacher trên bộ dữ liệu Xtrain, ytrain\n","teacher.fit(Xtrain,ytrain, batch_size=16, epochs=50)#,validation_data =(Xtest_teacher, ytest_teacher), shuffle = True,callbacks=[checkpoint],verbose=1)\n","teacher.save(path_model +'model_teacher.h5')\n","ypred = teacher.predict(Xtest)\n","ypred =np.argmax(ypred,axis =1)\n","\n","ytest_true =  np.argmax(ytest,axis =1)\n","\n","result22 = confusion_matrix(ytest_true,ypred)\n","print(result22)"],"metadata":{"id":"xFWAtxft30Gh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e31f0626-93ba-4ffc-db54-6f61c6d4c969"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 141ms/step - AUC: 0.6579 - categorical_accuracy: 0.6101 - loss: 0.6493\n","Epoch 2/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 134ms/step - AUC: 0.7817 - categorical_accuracy: 0.7154 - loss: 0.5684\n","Epoch 3/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 140ms/step - AUC: 0.7834 - categorical_accuracy: 0.7241 - loss: 0.5683\n","Epoch 4/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 138ms/step - AUC: 0.8012 - categorical_accuracy: 0.7416 - loss: 0.5485\n","Epoch 5/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 139ms/step - AUC: 0.7938 - categorical_accuracy: 0.7315 - loss: 0.5554\n","Epoch 6/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 132ms/step - AUC: 0.8171 - categorical_accuracy: 0.7492 - loss: 0.5296\n","Epoch 7/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 138ms/step - AUC: 0.8167 - categorical_accuracy: 0.7472 - loss: 0.5270\n","Epoch 8/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 144ms/step - AUC: 0.8286 - categorical_accuracy: 0.7665 - loss: 0.5142\n","Epoch 9/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 138ms/step - AUC: 0.8294 - categorical_accuracy: 0.7615 - loss: 0.5102\n","Epoch 10/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 133ms/step - AUC: 0.8455 - categorical_accuracy: 0.7768 - loss: 0.4892\n","Epoch 11/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 140ms/step - AUC: 0.8402 - categorical_accuracy: 0.7729 - loss: 0.4960\n","Epoch 12/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 142ms/step - AUC: 0.8452 - categorical_accuracy: 0.7774 - loss: 0.4900\n","Epoch 13/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 136ms/step - AUC: 0.8461 - categorical_accuracy: 0.7775 - loss: 0.4884\n","Epoch 14/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 139ms/step - AUC: 0.8523 - categorical_accuracy: 0.7789 - loss: 0.4789\n","Epoch 15/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 131ms/step - AUC: 0.8599 - categorical_accuracy: 0.7851 - loss: 0.4677\n","Epoch 16/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 140ms/step - AUC: 0.8630 - categorical_accuracy: 0.7846 - loss: 0.4642\n","Epoch 17/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 133ms/step - AUC: 0.8641 - categorical_accuracy: 0.7866 - loss: 0.4622\n","Epoch 18/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 128ms/step - AUC: 0.8530 - categorical_accuracy: 0.7872 - loss: 0.4775\n","Epoch 19/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 139ms/step - AUC: 0.8719 - categorical_accuracy: 0.8007 - loss: 0.4499\n","Epoch 20/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 133ms/step - AUC: 0.8737 - categorical_accuracy: 0.7932 - loss: 0.4482\n","Epoch 21/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 129ms/step - AUC: 0.8744 - categorical_accuracy: 0.7928 - loss: 0.4466\n","Epoch 22/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 142ms/step - AUC: 0.8738 - categorical_accuracy: 0.7943 - loss: 0.4477\n","Epoch 23/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 133ms/step - AUC: 0.8780 - categorical_accuracy: 0.8065 - loss: 0.4396\n","Epoch 24/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 133ms/step - AUC: 0.8842 - categorical_accuracy: 0.8059 - loss: 0.4302\n","Epoch 25/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 136ms/step - AUC: 0.8811 - categorical_accuracy: 0.8036 - loss: 0.4345\n","Epoch 26/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 131ms/step - AUC: 0.8792 - categorical_accuracy: 0.7961 - loss: 0.4389\n","Epoch 27/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 140ms/step - AUC: 0.8859 - categorical_accuracy: 0.8147 - loss: 0.4265\n","Epoch 28/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 139ms/step - AUC: 0.8958 - categorical_accuracy: 0.8247 - loss: 0.4079\n","Epoch 29/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 142ms/step - AUC: 0.8936 - categorical_accuracy: 0.8195 - loss: 0.4126\n","Epoch 30/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 158ms/step - AUC: 0.8944 - categorical_accuracy: 0.8172 - loss: 0.4109\n","Epoch 31/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 142ms/step - AUC: 0.8947 - categorical_accuracy: 0.8119 - loss: 0.4100\n","Epoch 32/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 129ms/step - AUC: 0.9011 - categorical_accuracy: 0.8236 - loss: 0.3982\n","Epoch 33/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 135ms/step - AUC: 0.8907 - categorical_accuracy: 0.8112 - loss: 0.4167\n","Epoch 34/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 137ms/step - AUC: 0.9023 - categorical_accuracy: 0.8175 - loss: 0.3958\n","Epoch 35/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 136ms/step - AUC: 0.8996 - categorical_accuracy: 0.8247 - loss: 0.4026\n","Epoch 36/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 135ms/step - AUC: 0.8962 - categorical_accuracy: 0.8213 - loss: 0.4079\n","Epoch 37/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 132ms/step - AUC: 0.8947 - categorical_accuracy: 0.8220 - loss: 0.4107\n","Epoch 38/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 140ms/step - AUC: 0.9062 - categorical_accuracy: 0.8288 - loss: 0.3886\n","Epoch 39/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 144ms/step - AUC: 0.9028 - categorical_accuracy: 0.8292 - loss: 0.3949\n","Epoch 40/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 134ms/step - AUC: 0.9009 - categorical_accuracy: 0.8201 - loss: 0.3984\n","Epoch 41/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 135ms/step - AUC: 0.9015 - categorical_accuracy: 0.8252 - loss: 0.3965\n","Epoch 42/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 131ms/step - AUC: 0.9070 - categorical_accuracy: 0.8265 - loss: 0.3867\n","Epoch 43/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 137ms/step - AUC: 0.9061 - categorical_accuracy: 0.8268 - loss: 0.3885\n","Epoch 44/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 137ms/step - AUC: 0.9114 - categorical_accuracy: 0.8286 - loss: 0.3774\n","Epoch 45/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 140ms/step - AUC: 0.9089 - categorical_accuracy: 0.8349 - loss: 0.3826\n","Epoch 46/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 142ms/step - AUC: 0.9137 - categorical_accuracy: 0.8326 - loss: 0.3742\n","Epoch 47/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 142ms/step - AUC: 0.9084 - categorical_accuracy: 0.8289 - loss: 0.3835\n","Epoch 48/50\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 142ms/step - AUC: 0.9069 - categorical_accuracy: 0.8254 - loss: 0.3860\n","Epoch 49/50\n","\u001b[1m209/422\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 153ms/step - AUC: 0.9213 - categorical_accuracy: 0.8387 - loss: 0.3557"]}]},{"cell_type":"code","source":["# Huấn luyện model student học chuyển giao từ teacher\n","teacher_model = models.load_model(path_model + 'model_teacher.h5') # Tải model teacher đã được huấn luyện\n","distiller = Distiller(student=student, teacher=teacher_model)\n","distiller.compile(\n","      student_loss_fn= keras.losses.CategoricalCrossentropy(from_logits=True),\n","      #student_loss_fn= keras.losses.BinaryCrossentropy(from_logits=True),\n","      optimizer=keras.optimizers.AdamW(learning_rate = 0.0001),\n","      metrics=[\n","              \"categorical_accuracy\",\n","              \"AUC\",\n","              ], # , f1\n","      distillation_loss_fn=keras.losses.KLDivergence(),\n","      alpha=0.1,\n","      temperature=10\n","      )\n","\n","history_KD = distiller.fit(Xtrain,ytrain, batch_size=16,epochs=50)#, validation_data =(Xtest_student, ytest_student), callbacks=[checkpoint],verbose=1)\n","result2 = distiller.evaluate(Xtest, ytest)#, validation_data=(X_test,Y_test), shuffle = True,callbacks=[checkpoint],verbose=1)\n","f = open(result_test, 'a+', encoding='UTF-8')\n","f.write(\"\\n Independent model KD_BiLSTM  \\n \")\n","s = str(result2)\n","f.write(s)\n","f.close()\n","\n","ypred = student.predict(Xtest)\n","ypred =np.argmax(ypred,axis =1)\n","\n","ytest_true =  np.argmax(ytest,axis =1)\n","\n","result22 = confusion_matrix(ytest_true,ypred)\n","print(result22)\n","f = open(result_test, 'a+', encoding='UTF-8')\n","f.write(\"\\n confusion_matrix KD_BIlstm: Student \\n \")\n","s = str(result22)\n","f.write(s)\n","f.close()\n","# save model student\n","student.save(path_model +\"KD_LSTM.h5\")"],"metadata":{"id":"s7qr8EjU3Wze"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Tải model student dự đoán cho dữ liệu test**"],"metadata":{"id":"JAdVVeSi-E1d"}},{"cell_type":"code","source":["from keras import models\n","model_KD = models.load_model(path_model +\"KD_LSTM.h5\")\n","y_prob_KD = model_KD.predict(Xtest)\n","pd.DataFrame(y_prob_KD[:,1], columns=['KD_pred']).to_csv(path_result +'KD_prediction.csv')"],"metadata":{"id":"j4qmIgzS3KWR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Huấn luyện độc lập mô hình Teacher, student để so sánh với mô hình chắt lọc tri thức**"],"metadata":{"id":"UdlROwmPHyWQ"}},{"cell_type":"code","source":["# Model Student test independent base on Student dataset\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dropout, Flatten, Dense\n","# Define your student model\n","model_student = Sequential()\n","model_student.add(Embedding(vocab_size + 1, 300, input_length=MAX_SEQUENCE_LENGTH_student, trainable=True))\n","model_student.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n","model_student.add(Dropout(0.2))\n","model_student.add(Flatten())\n","model_student.add(Dense(128, activation='relu'))\n","model_student.add(Dropout(0.2))\n","model_student.add(Dense(2, activation='softmax'))\n","\n","metrics=[\n","          \"accuracy\",\n","          \"AUC\",\n","          ]\n","model_student.compile(optimizer=keras.optimizers.AdamW(learning_rate = 0.0001), loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=metrics)\n","\n","# Train your model\n","history_model_student = model_student.fit(Xtrain_student, ytrain_student, batch_size=16, epochs=50, validation_data=(Xtest_student, ytest_student),callbacks=[checkpoint],verbose=1)\n","\n","# Evaluate your model\n","result2 = model_student.evaluate(Xtest_student, ytest_student)\n","\n","# Save evaluation results to a file\n","with open(result_test, 'a+', encoding='UTF-8') as f:\n","    f.write(\"\\n Model Student: Test independent \\n \")\n","    f.write(str(result2))\n","\n","# Make predictions\n","ypred = model_student.predict(Xtest_student)\n","ypred = np.argmax(ypred, axis=1)\n","\n","# Calculate confusion matrix\n","result22 = confusion_matrix(np.argmax(ytest_student, axis=1), ypred)\n","print(result22)\n","# Save confusion matrix to a file\n","with open(result_test, 'a+', encoding='UTF-8') as f:\n","    f.write(\"\\n model Student: Confusion matrix \\n \")\n","    f.write(str(result22))\n","model_student.save(path +\"model_student.h5\")"],"metadata":{"id":"OeH-x7M98No9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model Teacher test independent base on Student dataset\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dropout, Flatten, Dense\n","\n","# Define your teacher model\n","model_teacher = Sequential()\n","model_teacher.add(Embedding(vocab_size + 1, 300, input_length=MAX_SEQUENCE_LENGTH_student, trainable=True))\n","model_teacher.add(LSTM(300, dropout=0.2, recurrent_dropout=0.2))\n","model_teacher.add(Dropout(0.2))\n","model_teacher.add(Flatten())\n","model_teacher.add(Dense(128, activation='relu'))\n","model_teacher.add(Dropout(0.2))\n","model_teacher.add(Dense(2, activation='softmax'))\n","\n","metrics=[\n","          \"accuracy\",\n","          \"AUC\",\n","          ]\n","model_teacher.compile(optimizer=keras.optimizers.AdamW(learning_rate = 0.0001), loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=metrics)\n","\n","# Train your model\n","history_model_teacher = model_teacher.fit(Xtrain_student, ytrain_student, batch_size=16, epochs=50, validation_data=(Xtest_student, ytest_student),callbacks=[checkpoint],verbose=1)\n","\n","# Evaluate your model\n","result2 = model_teacher.evaluate(Xtest_student, ytest_student)\n","\n","# Save evaluation results to a file\n","with open(result_test, 'a+', encoding='UTF-8') as f:\n","    f.write(\"\\n Model teacher: Independent test \\n \")\n","    f.write(str(result2))\n","\n","# Make predictions\n","ypred = model_teacher.predict(Xtest_student)\n","ypred = np.argmax(ypred, axis=1)\n","\n","# Calculate confusion matrix\n","result22 = confusion_matrix(np.argmax(ytest_student, axis=1), ypred)\n","print(result22)\n","# Save confusion matrix to a file\n","with open(result_test, 'a+', encoding='UTF-8') as f:\n","    f.write(\"\\n Model teacher: Confusion matric \\n \")\n","    f.write(str(result22))\n","model_teacher.save(path +\"model_teacher.h5\")"],"metadata":{"id":"CdBuBN0UD3SK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cross-validation teacher\n","\n","from sklearn.model_selection import KFold\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dropout, Flatten, Dense\n","from sklearn.metrics import confusion_matrix\n","\n","\n","kf = KFold(n_splits=num_folds, shuffle=True)\n","\n","X_student = Xtrain_student\n","Y_student = ytrain_student\n","\n","for train_index_student, test_index_student in kf.split(X_student,Y_student):\n","    X_train_student, X_test_student =X_student[train_index_student], X_student[test_index_student]\n","    Y_train_student, Y_test_student = Y_student[train_index_student], Y_student[test_index_student]\n","\n","\n","\n","    model_teacher = Sequential()\n","    model_teacher.add(Embedding(vocab_size + 1, 300, input_length=MAX_SEQUENCE_LENGTH_student, trainable=True))\n","    model_teacher.add(LSTM(300, dropout=0.2, recurrent_dropout=0.2))\n","    model_teacher.add(Dropout(0.2))\n","    model_teacher.add(Flatten())\n","    model_teacher.add(Dense(128, activation='relu'))\n","    model_teacher.add(Dropout(0.2))\n","    model_teacher.add(Dense(2, activation='softmax'))\n","    model_teacher.compile(optimizer=keras.optimizers.AdamW(learning_rate = 0.0001), loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy','AUC'])\n","    # Train your model\n","    history_model_teacher = model_teacher.fit(X_train_student, Y_train_student, batch_size=16, epochs=50, validation_data=(X_test_student, Y_test_student),callbacks=[checkpoint],verbose=1)\n","    # Evaluate your model\n","    result2 = model_teacher.evaluate(X_test_student, Y_test_student)\n","    # Save evaluation results to a file\n","    with open(result_test, 'a+', encoding='UTF-8') as f:\n","        f.write(\"\\n Cross validation Model teacher \\n \")\n","        f.write(str(result2))\n","    # Make predictions\n","    ypred = model_teacher.predict(X_test_student)\n","    ypred = np.argmax(ypred, axis=1)\n","    # Calculate confusion matrix\n","    result22 = confusion_matrix(np.argmax(Y_test_student, axis=1), ypred)\n","    print(result22)\n","    # Save confusion matrix to a file\n","    with open(result_test, 'a+', encoding='UTF-8') as f:\n","        f.write(\"\\n model teacher \\n \")\n","        f.write(str(result22))"],"metadata":{"id":"8BJOw4zay7_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# kiểm thử chéo model sinh viên\n","from sklearn.model_selection import KFold\n","num_folds = 5\n","kf = KFold(n_splits=num_folds, shuffle=True)\n","\n","X_student = Xtrain_student\n","Y_student = ytrain_student\n","\n","for train_index_student, test_index_student in kf.split(X_student,Y_student):\n","    X_train_student, X_test_student =X_student[train_index_student], X_student[test_index_student]\n","    Y_train_student, Y_test_student = Y_student[train_index_student], Y_student[test_index_student]\n","    model_student = Sequential()\n","    model_student.add(Embedding(vocab_size + 1, 300, input_length=MAX_SEQUENCE_LENGTH_student, trainable=True))\n","    model_student.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n","    model_student.add(Dropout(0.2))\n","    model_student.add(Flatten())\n","    model_student.add(Dense(128, activation='relu'))\n","    model_student.add(Dropout(0.2))\n","    model_student.add(Dense(2, activation='softmax'))\n","    model_student.compile(optimizer=keras.optimizers.AdamW(learning_rate = 0.0001), loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy','AUC'])\n","\n","    # Train your model\n","    history_model_student = model_student.fit(X_train_student, Y_train_student, batch_size=16, epochs=50, validation_data=(X_test_student, Y_test_student),callbacks=[checkpoint],verbose=1)\n","\n","    # Evaluate your model\n","    result2 = model_student.evaluate(X_test_student, Y_test_student)\n","\n","    # Save evaluation results to a file\n","    with open(result_test, 'a+', encoding='UTF-8') as f:\n","        f.write(\"\\n Cross validation Model Student \\n \")\n","        f.write(str(result2))\n","\n","    # Make predictions\n","    ypred = model_student.predict(X_test_student)\n","    ypred = np.argmax(ypred, axis=1)\n","\n","    # Calculate confusion matrix\n","    result22 = confusion_matrix(np.argmax(Y_test_student, axis=1), ypred)\n","    print(result22)\n","    # Save confusion matrix to a file\n","    with open(result_test, 'a+', encoding='UTF-8') as f:\n","        f.write(\"\\n model Student \\n \")\n","        f.write(str(result22))\n"],"metadata":{"id":"0hlotKOGzLta"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Models predict and draw ROC"],"metadata":{"id":"83ZNqYjOumUG"}},{"cell_type":"code","source":["from keras import models\n","model_teacher = models.load_model(path +\"model_teacher.h5\")\n","\n","\n","#y_prob_teacher = np.array(list(map(predict_prob, model_teacher.predict(Xtest_student))))\n","y_prob_teacher = model_teacher.predict(Xtest_student)\n","pd.DataFrame(y_prob_teacher[:,1], columns=['predictions']).to_csv(path +'teacher_prediction.csv')"],"metadata":{"id":"7GAW5EM3IGsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras import models\n","model_student = models.load_model(path +\"model_student.h5\")\n","\n","\n","#y_prob_st = np.array(list(map(predict_prob, model_student.predict(Xtest_student))))\n","y_prob_st =model_student.predict(Xtest_student)\n","pd.DataFrame(y_prob_st[:,1], columns=['student_pred']).to_csv(path +'student_prediction.csv')"],"metadata":{"id":"3RgCYRyoyp04"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras import models\n","model_KD = models.load_model(path +\"KD_LSTM.h5\")\n","y_prob_KD = model_KD.predict(Xtest_student)\n","pd.DataFrame(y_prob_KD[:,1], columns=['KD_pred']).to_csv(path +'KD_prediction.csv')"],"metadata":{"id":"80y0KahDumUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"MQO--cCU3W5c"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","import numpy as np\n","from keras import models\n","from sklearn import metrics\n","# Generate some sample data (replace this with your actual data)\n","# Assuming y_true and y_pred are your true labels and predicted probabilities respectively\n","\n","\n","y_true=ytest_student[:,1]\n","\n","# Calculate ROC curve and AUC for Teacher\n","\n","#fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n","fpr_teacher, tpr_teacher, thresholds_teacher  = metrics.roc_curve(y_true, y_prob_teacher[:,1])\n","roc_auc_teacher = auc(fpr_teacher, tpr_teacher)\n","\n","# Calculate ROC curve and AUC for Student\n","fpr_student, tpr_student, thresholds_student = metrics.roc_curve(y_true, y_prob_st[:,1])\n","roc_auc_student = auc(fpr_student, tpr_student)\n","# Calculate ROC curve and AUC for Knowlege distillation\n","fpr_KD, tpr_KD, thresholds_KD = metrics.roc_curve(y_true, y_prob_KD[:,1])\n","roc_auc_KD = auc(fpr_KD, tpr_KD)\n","# Plot ROC curves\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr_teacher, tpr_teacher, color='red', lw=2, label='Teacher model, AUC = {:.4f}'.format(0.903))\n","plt.plot(fpr_student, tpr_student,  color='red', lw=2, label='Student model, AUC = {:.4f}'.format(roc_auc_student))\n","plt.plot(fpr_KD, tpr_KD, color='green',lw=2, label='Knowledge Distillation, AUC = {:.4f}'.format(roc_auc_KD))\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC)')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"metadata":{"id":"CVvHzyY4wkjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["distiller.summary()"],"metadata":{"id":"kcgAh85m1t7u"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}